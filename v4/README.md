# 4.22-4.27 反思
## 4.22-4.24
经过和老师的讨论，发现我自己说不清楚模态补偿模块怎么实现促进模态一致性和保留模态特异性信息的平衡。于是又恶补论文。\
把原来的mse loss改为各自的模态分类的交叉熵损失，让补偿后的特征更具模态判别性。相比不加，能提升5个百分点，但还是在30%左右。\
以后的版本都没再加融合部分，因为发现作用不大。先一个模块一个模块的抠。\
## 4.26
又考虑到会不会是基线的问题，我又把基线进行了调整，去掉最大池化层，改了第一层的卷积核和stride。\
还考虑到数据的问题，下游训练一直是1%的训练数据。训练和测试分开之后，只有125个训练样本，而测试要200000左右个样本，根本不是1:99！于是用20%训练数据
**大突破！**
